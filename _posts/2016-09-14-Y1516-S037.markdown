---
layout: post
title: "Minority Report 1 - évaluation de différents modes d'indexation d'images"
date: 2016-09-14 17:51:17
categories: [dispo, gmd,web]
pid: Y1516-S037
type: Engineering
contact: Alain Giboin
---
       
Les personnages du film Minority Report contrôlent les écrans avec les yeux. Pour sélectionner des images, pourrait-on, avec les eye trackers actuels, remplacer le clic souris par le seul regard ?
Vous comparerez les résultats de sélection des images par 3 modes d’interaction sur 2 bases d’images en termes d’efficacité. Des biais liés à la subjectivité des recherches seront à prendre en compte. Afin de faciliter la comparaison des trajectoires du regard dans ces 2 contextes, il faudra réaliser une interface de visualisation des données du regard associées aux paires d’images présentées aux utilisateurs (nombre de fixation, trajectoires…). Cette partie pourra être testée sur le PFE Minority Report 2, qui implique aussi l’étude du regard dans un autre contexte de recherche d’images.

#### Compétences Requises
•	C++
•	La connaissance de l'IDE Qt Creator serait un plus
•	Installation rapide de logiciels et vérification de compatibilité
       o	SDK analysis (reconnaissance faciale) pour eye tracker
       o	Windows 7 / Windows 10 pour la surface tactile (vérifier la compatibilité avec l’application)
•	Compétences en IHM
       o	Élaboration et passation de protocoles d’expérimentation avec utilisateur
       o	Technologies d’interaction
•	Notions de statistique


#### Besoins Clients
Dans le but d’annoter des images par le regard, une étude de data mining que nous avons réalisée (1) a montré qu’il était possible d’inférer à partir des seules données du regard, l’image que l’utilisateur va choisir parmi 2 images présentées, en moins d’une seconde, dans le cadre de recherche d’images illustrant une catégorie donnée (animaux, personnes, véhicules, mobilier). L’étude des données du regard s’est faite à posteriori pour extraire une règle généralisable à un ensemble d’utilisateurs, quelle que soit la catégorie à chercher. 70% des inférences étaient correctes, sur les 6960 réalisées.

Désormais, cette mesure du regard inférant le choix de l’utilisateur est intégrée au système afin que les images suivantes soient sélectionnées de manière plus pertinente.
 
Dans ce PFE nous vous proposons de réaliser deux études comparatives :
•	La première étude consistera à réaliser un protocole de test de classification d’images utilisant la mesure intégrée (*) qui permettra de. Les résultats de cette étude seront comparés avec  les résultats obtenus dans l’étude (1). 
•	La seconde étude consistera à  comparer les résultats obtenus avec une sélection par le regard (incertaine) avec une sélection avec d’autres moyens d’interaction. Ce sera l’occasion d’évaluer l’impact de l’utilisation de ces moyens d’interaction sur le mouvement des yeux. Cette étude sera également menée sur une base d’images de recette de cuisine, qui est porteuse de notions subjectives (voir étude (2)).

Afin de permettre à des  data analysts (**) de visualiser et analyser ces données du regard, vous aurez à  concevoir une interface de visualisation permettant d’afficher les paires d’images d’un utilisateur donné avec une possibilité de sélectionner les caractéristiques du regard disponibles (dilatation de la pupille, nombre de fixations, etc.). 

                  (*) Ce protocole pourra être réalisé dans le cadre des TP du module TIM
                  (**) Les étudiants du PFE Minority Report 2 pourront avoir besoin de cette 
                       fonctionnalité. Ils seront alors vos clients. Un moyen d’évaluation
                       de votre travail pourra être le bon fonctionnement de cette partie
                       dans le sujet PFE Minority Report 2.

#### Résultats Attendus
-	Comparaison des performances de classification entre la présentation aléatoire de paires d’images prédéterminées (1) et la présentation interactive d’images intégrant la décision par le regard.

-	Comparaison des performances de classification entre les différents modes d’interaction qui seront testés (souris, interface tactile, regard).

-	Analyse des retours utilisateur sur leurs préférences entre les 3 modes d’interaction.

-	Constitution d’une base d’images de cuisine, permettant de répondre aux exigences du protocole (les images sont fournies, il s’agit de les regrouper de manière optimale). Elle peut se faire en collaboration avec les étudiants choisissant le PFE Minority Report 2.

1er protocole : comparaison entre les différents modes d’interaction
•	1er rapport :
A.	questionnaire utilisateurs + réponses
B.	analyse de l’impact des catégories d’utilisateurs (déterminées par le questionnaire préliminaire) sur les résultats obtenus
C.	questionnaire feedback utilisateur + analyse des réponses
D.	étude comparative des performances de classification entre les différents modes d’interaction avec les résultats (1)

•	2e rapport :
A.	Maquettage et choix d’implémentation de l’interface de visualisation
B.	Retours « client » des étudiants du PFE2 

•	Autres rendus : 
A.	vidéo de démonstration du protocole à présenter aux utilisateurs
B.	programme c++ permettant d’intégrer le mode « surface tactile » à l’expérience fournie avec l’enregistrement du regard en parallèle

2e  protocole : extension aux images de recettes
•	Rapports : 
cf 1er protocole, en adaptant à la subjectivité inhérente au contexte de recherche d’images de cuisine
•	Autres rendus : 
constitution d’une base permettant de répondre aux exigences du protocole (les images sont fournies, il s’agit de les regrouper de manière optimale)
     

#### Informations Administratives
  * Contact : Alain Giboin <alain.giboin@inria.fr>
  * Identifiant sujet : `Y1516-S037`
  * Type : Engineering
  * Parcours Recommandés : GMD,WEB
     