---
layout: post
title: "Algorithmes d'apprentissage sur infrastructure embarquée Jetson TX1"
date: 2017-09-20 21:45:46
categories: [dispo, al,sd]
pid: Y1718-S046
type: Engineering
contact: Johan Montagnat
---
       
L'objet de ce stage sera d'étudier la performance de différentes bibliothèques logicielles standard d'apprentissage sur une architecture embarquée légère de type Jetson TX1 qui exploite un GPU pour l'accélération des calculs. Les étudiants devront à la fois disposer de la maîtrise système (Linux) pour déployer et paramétrer différentes bibliothèques et être capable de planifier et de conduire des plans d'expérience pour comparer la performance de différentes solutions à partir de benchmarks de référence. Un objectif secondaire est d'exploiter les possibilités de parallélisation des calculs d'apprentissage sur plusieurs modules Jetson simultanément, afin de consituer une plateforme parallèle extensible à moindre coût.

Si les algorithmes d'apprentissage, et en particulier l'apprentissage profond (deep learning), ont rencontré des succès considérables ces dernières années dans de nombreux domaines, le coût des algorithmes utilisés (en puissance de calcul et donc en consommation électrique) est rarement mis en avant. De fait, les résultats emblématiques font souvent appel à des puissances pétaflopiques complètement inaccessibles à un grand nombre d'applications. L'enjeu devient souvent de définir un compromis acceptable entre puissance de calcul (qui influe directement sur la qualité du résultat) et coût. Des accélérateurs sont communément utilisés pour les algorithmes d'apprentissage, mais malgré l'efficacité reconnue des GPUs les besoins énergétiques restent souvent considérables.

L'objet de ce stage sera d'étudier la faisabilité et la performance du déploiement de différentes bibliothèques logicielles standard d'apprentissage qui exploitent CUDA (GPU nVIdia), telles que Theano, Caffe, TensorFlow..., sur une architecture embarquée légère de type Jetson TX1. Ces composants à bas coût et basse consommation en font des cibles idéales pour le déploiement d'applications utilisant l'apprentissage dans une contexte de capacité énergétique limitée. Les étudiants devront à la fois disposer de la maîtrise système (Linux) pour déployer et paramétrer différentes bibliothèques et être capable de planifier et de conduire des plans d'expérience pour comparer la performance de différentes solutions à partir de réseaux de référence (tels que NMIST). Un objectif secondaire est d'exploiter les possibilités de parallélisation des calculs d'apprentissage sur plusieurs modules Jetson simultanément, afin de consituer une plateforme parallèle extensible à moindre coût.

Etapes:
  - Etude des bibliothèques logicielles d'apprentissage les plus communément utilisées
  - Installation d'un noyau linux sur les kits Jetson
  - Déploiement et configuratoin de différentes bibliothèques ciblées
  - Définition et exécution d'une campagne de test de performances à partir de benchmarks standards
  - Etude bibliographique sur les possibilités de mise en oeuvre en parallèle et expérimentation

#### Compétences Requises
Linux. Notions de parallélisation. Notions en CUDA ou machine learning appréciées.



     

#### Informations Administratives
  * Contact : Johan Montagnat <johan.montagnat@cnrs.fr>
  * Identifiant sujet : `Y1718-S046`
  * Type : Engineering
  * Parcours Recommandés : AL,SD
  * Équipe: SPARKS

#### Références

  * [https://www.semanticscholar.org/paper/Are-Very-Deep-Neural-Networks-Feasible-on-Mobile-D-Rallapalli-Qiu/d7896d6be118386a1f76f389210ca4e3a87b0d4a](https://www.semanticscholar.org/paper/Are-Very-Deep-Neural-Networks-Feasible-on-Mobile-D-Rallapalli-Qiu/d7896d6be118386a1f76f389210ca4e3a87b0d4a)
  * [http://engineering.skymind.io/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks](http://engineering.skymind.io/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks)
  * [http://www.deeplearningbook.org/](http://www.deeplearningbook.org/)

#### Besoins Clients
  - Déploiement de piles logicielles exploitant CUDA sur un système embarqué
  - Analyse de performance
  - Comparaison des différentes solutions exploitables

#### Résultats Attendus
  - Système installé et configuré
  - Documentation de la procédure d'installation
  - Description des benchmarks
  - Rapport de performances
  - Etude bibliographique des possibilités de parallélisation
     