---
layout: post
title: "UbiUnity: Simulation d'environnements 3D pour l'informatique ambiante"
date: 2014-09-15 11:17:01
categories: [dispo, iam, al, caspar, gmd]
pid: Y1415-S025
type: Engineering
contact: Stéphane Lavirotte
---
       
Stéphane Lavirotte et Jean-Yves Tigli : Equipe Rainbow, Laboratoire I3S

De nombreuses initiatives visent à la mise en œuvre d’espaces ambiants (les Living Labs  en Europe par exemple ou les Smart Cities). Ces infrastructures permettent d’effectuer des recherches sur le long terme tant sur les aspects de l’étude des comportements humains que des algorithmes mis en œuvre pour la gestion de ces espaces ambiants. Mais la conception, le développement et le déploiement de ces espaces ambiants est une tâche d’ingénierie complexe.
Ces bancs d’essais pour l’expérimentation ou ces installations que sont les Living Labs ou les Smart Cities ont plusieurs inconvénients : investissements lourds, variété limité de capteurs et actionneurs, mises à jour complexes et limitées, dynamique de l'environnement limitée, échelle de déploiement. Il est donc intéressant de pouvoir disposer de simulateurs permettant de pallier aux limitations des espaces ambiants déployés physiquement.
Un premier travail a été réalisé l'an dernier sur ce sujet qui a conduit à la mise en œuvre d'un prototype permettant de simuler des espaces ambiants. Ce simulateur est basé sur l'environnement Unity3D pour la gestion des scènes 3D. Une scène peut être instrumentée de différents services qui seront activés en fonction de la position dans la scène pour simuler la découverte des services liés aux dispositifs présents dans la scène.

L'objectif de ce projet est de poursuivre le travail déjà initié et à le compléter suivant plusieurs axes. Le premier travail attendu consistera à :
-	Reprendre et étudier le travail réalisé.
-	Mettre en place un premier démonstrateur en instrumentant une ou plusieurs scènes 3D existantes à l’aide du framework développé (attacher des services aux dispositifs virtuels présents dans la scène).
-	Démarrer les services dynamiquement en fonction de la position de l’avatar dans la scène et de sa distance aux objets virtuels supportant les services associés

Le deuxième axe du projet est d’ajouter la possibilité d’intégrer automatiquement des avatars d’objets physiques réels dans la scène 3D. Par exemple, si on démarre un objet physique réel dans l’environnement d’expérimentation, celui-ci devra être détecté par le la scène 3D et être intégré automatiquement dans l’environnement virtuel. Ceci permettra par exemple d’avoir une vision de l’état de l’environnement des objets connectés à distance (si les objets physique sont à un endroit géographique et l’environnement 3D situé dans une autre ville), sans avoir de besoin de l’utilisation de caméra et de système de visioconférence.

La réalisation de ces travaux devra se faire en portant une attention toute particulière aux performances de la simulation (les travaux existants répondent déjà à ce critère, donc les extensions le devront aussi) en évaluant les impacts en terme fluidité de la simulation et des débits réseaux dans le cas de simulation à distance.

#### Compétences Requises
Les compétences attendues pour traiter ce sujet sont :
-	Capacité à apprendre de nouveaux outils ou environnements de développement (unity3D)
-	Programmation orientée objet ; la connaissance de C# est un plus
-	Des compétences personnelles comme : initiative et force de proposition, autonomie dans le travail, sens de l’organisation, rigueur et méthodologie de développement et d’évaluation des résultats, …


#### Besoins Clients
- Mise en place d’un démonstrateur dès le démarrage du projet
- Etude et mise en œuvre de la fonctionnalité d’avatar d’objet réel avec réplication des services dans l’environnement 3D (une valeur émise par un capteur ou l’action réalisée sur un objet physique doit être communiquée dans l’environnement virtuel 3D).
- Etude et évaluation rigoureuse des performances pour une utilisation avec communication à distance de la simulation.

#### Résultats Attendus
- Démonstrateur fonctionnel dès le démarrage du projet à partir des briques existantes (instrumentation de scènes existantes à l’aide du framework mis en place)
- Ajouts des fonctionnalités attendues à ce démonstrateur (démarrage dynamique des services associés aux objets, …)
- Développement du framework pour l’intégration automatique dans la scène 3D d’avatars d’objets physiques réels.
- Mesure de l’impact sur les performances de la simulation
- Démonstrateur final fonctionnant sur au moins 2 scènes intégrant l’ensemble des fonctionnalités développées dans le projet
- Rédaction d’un rapport sur l’analyse des performances et d’une documentation pour la mise en œuvre d’autres scènes
     

#### Informations Administratives
  * Contact : Stéphane Lavirotte <stephane.lavirotte@unice.fr>
  * Identifiant sujet : `Y1415-S025`
  * Type : Engineering
  * Parcours Recommandés : IAM, AL, CASPAR, GMD
     